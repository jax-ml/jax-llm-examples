[project]
name = "llama3_jax"
version = "0.1.0"
description = ""
authors = [
    { name = "Robert Dyro" },
]
readme = "README.md"
requires-python = ">=3.10"
license = { text = "Apache-2.0" }

dependencies = [
    "datasets",
    "etils",
    "gcsfs",
    "huggingface-hub",
    "jax",
    "numpy",
    "orbax-checkpoint",
    "torch",
    "tqdm",
    "transformers",  # for the model config and the tokenizer
]

# we don't need CUDA torch
[[tool.uv.index]]
name = "pytorch"
url = "https://download.pytorch.org/whl/cpu"

[build-system]
requires = ["setuptools>=61.0.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.black]
line-length = 120

[tool.ruff]
line-length = 120
indent-width = 4

[tool.ruff.lint]
ignore = [
    "E731", # lambdas expression instead of def
]

[tool.setuptools]
packages = ["llama3_jax"]

[tool.setuptools.dynamic]
dependencies = { file = ["pyproject.toml"] }
